{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8f0b934-bbf0-46bc-b21d-43c00ad980ac",
   "metadata": {},
   "source": [
    "# Stage 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f626a4-1b4f-41bf-8134-5016e5d5e28c",
   "metadata": {},
   "source": [
    "Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17b5ba29-7582-4273-be4b-e6d318ea652b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "from joblib import Parallel, delayed\n",
    "from functools import partial\n",
    "import scipy.sparse\n",
    "import seaborn as sns\n",
    "import scanpy_gpu_funcs as rsf\n",
    "import cudf\n",
    "import cupy as cp\n",
    "from cuml.decomposition import PCA\n",
    "from scipy.sparse import issparse\n",
    "from SCTransform import SCTransform\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "# import bbknn\n",
    "\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib import rcParams\n",
    "# sc.set_figure_params(dpi= 100, dpi_save = 300)\n",
    "# rcParams['figure.figsize'] = 5,5\n",
    "\n",
    "# import rmm\n",
    "# rmm.reinitialize(\n",
    "#     managed_memory=True, # Allows oversubscription\n",
    "#     pool_allocator=False, # default is False\n",
    "#     devices=0, # GPU device IDs to register. By default registers only GPU 0.\n",
    "# )\n",
    "# cp.cuda.set_allocator(rmm.rmm_cupy_allocator)\n",
    "\n",
    "os.chdir('/active/paper/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf510ff0-3ea7-4123-9b76-53339c9bb44a",
   "metadata": {},
   "source": [
    "# Logreg counts function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f2f7473-a270-4b8d-ba96-368a8de65209",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_counts_for_logreg(adata):\n",
    "    # log transform the counts\n",
    "    adata.X = adata.layers['counts'].copy()\n",
    "    if 'log1p' in adata.uns.keys(): \n",
    "        del adata.uns['log1p']\n",
    "    sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "    sc.pp.log1p(adata)\n",
    "    # create lognorm_counts\n",
    "    lognorm_counts = pd.DataFrame(adata.X.A, index=adata.obs_names, columns=adata.var_names)\n",
    "    # restore original counts\n",
    "    adata.X = adata.layers['counts'].copy()\n",
    "    return(lognorm_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376d0ff0-a995-49c9-bee9-4a2fc26c236b",
   "metadata": {},
   "source": [
    "# Log reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2084db77-7732-47ae-b286-34204ae64b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from cuml.linear_model import LogisticRegression\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import colors\n",
    "from matplotlib import cm\n",
    "from sklearn.metrics import precision_recall_curve    \n",
    "\n",
    "def logistic_model(data, cell_types, sparsity=0.2, fraction=0.5):\n",
    "    X = data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, cell_types, test_size=fraction, random_state=1)\n",
    "    lr = LogisticRegression(penalty='l1', C=sparsity, solver='qn', max_iter=10000)\n",
    "    lr.fit(X_train, y_train)\n",
    "    y_prob = lr.predict_proba(X_test)\n",
    "    lr.coef_ = lr.coef_.transpose()\n",
    "    lr_res = pd.DataFrame.from_records(lr.coef_, columns=X.columns)\n",
    "\n",
    "    return(y_prob, y_test, lr_res, lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8843e32c-e094-46bc-ba1a-3d6811a5d99a",
   "metadata": {},
   "source": [
    "# SCT and cluster function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6e34a896-ab2f-43e3-80ee-9ea87ddb7fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sct_cluster(input_adata, res = 0.1, n_HVG = 5000):\n",
    "    \n",
    "    adata = input_adata.copy()\n",
    "    \n",
    "    # find var genes\n",
    "    # sc.pp.highly_variable_genes(adata, \n",
    "    #                             flavor='seurat_v3', \n",
    "    #                             n_top_genes=n_HVG, \n",
    "    #                             batch_key='sample_id', \n",
    "    #                             span=1)\n",
    "    \n",
    "    # SCTransform\n",
    "    # if run_SCT:\n",
    "    # create raw backup\n",
    "    # adata.raw = adata.copy()\n",
    "    # subset to HVG\n",
    "    # adata = adata[:,adata.var['highly_variable']].copy()\n",
    "    # run SCT\n",
    "    SCTransform(adata, \n",
    "            min_cells=100, \n",
    "            gmean_eps=1, \n",
    "            n_genes=None, \n",
    "            n_cells=None, # use all cells\n",
    "            bin_size=100000, \n",
    "            bw_adjust=3, \n",
    "            inplace=True)\n",
    "        # store SCT layer\n",
    "        # adata.layers['SCT'] = adata.X.copy()\n",
    "    # else:\n",
    "    #     adata.X = adata.layers['SCT'].copy()\n",
    "\n",
    "    # delete any 'leiden_' columns\n",
    "    adata.obs = adata.obs[adata.obs.columns.drop(list(adata.obs.filter(regex='^leiden_')))]\n",
    "\n",
    "    sc.pp.pca(adata, random_state=1, use_highly_variable=False) # they are all variable\n",
    "    sc.pp.neighbors(adata, method='rapids', random_state=1, n_neighbors=100)\n",
    "    sc.tl.umap(adata, method='rapids', random_state=1)\n",
    "    rsf.leiden(adata, resolution = res)\n",
    "    \n",
    "    n_clusters = len(adata.obs['leiden'].unique())\n",
    "    \n",
    "    # keep increasing the resolution until more than 1 cluster identified\n",
    "    while n_clusters == 1:\n",
    "        res = res + 0.1\n",
    "        rsf.leiden(adata, resolution = res)\n",
    "        n_clusters = len(adata.obs['leiden'].unique())\n",
    "        \n",
    "    leiden = adata.obs['leiden'].astype('str')\n",
    "    \n",
    "    # restore raw counts\n",
    "    # adata.X = adata.layers['counts'].copy()\n",
    "    \n",
    "    return(leiden, res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eae51c7-ddf5-4a40-ab67-9718021497ae",
   "metadata": {},
   "source": [
    "# Decide cluster outcome function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "daf2e29f-f358-48c7-8321-d373a8b19cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decide_cluster_outcome(input_adata, leiden, parent_cluster):\n",
    "    y_prob, y_test, lr_res, lr = logistic_model(log_counts_for_logreg(input_adata), \n",
    "                                                leiden.astype('int'))\n",
    "\n",
    "    f1_max = {}\n",
    "    for i, cell_type in enumerate(lr.classes_):\n",
    "        \n",
    "        if (y_test == lr.classes_[i]).sum() < 200:\n",
    "            f1_max[cell_type] = 0\n",
    "        else:\n",
    "            precision, recall, thresholds = precision_recall_curve(y_test == cell_type, y_prob[:, i])\n",
    "            f1_scores = [metrics.fbeta_score(y_test == cell_type, y_prob[:, i] > t, beta=1, zero_division=0) for t in np.random.choice(thresholds, 100)]\n",
    "            f1_max[cell_type] = f1_scores[np.argmax(f1_scores)]\n",
    "\n",
    "    print(f1_max)\n",
    "    \n",
    "    leiden = pd.DataFrame(leiden)\n",
    "\n",
    "    for key, f1 in f1_max.items():\n",
    "        if f1 >= 0.8:\n",
    "            # if leiden.loc[leiden['leiden'] == str(key), 'leiden'].shape[0] < 200:\n",
    "                # leiden.loc[leiden['leiden'] == str(key), 'leiden'] = parent_cluster + '_' + leiden.loc[leiden['leiden'] == str(key), 'leiden'] + '_FINAL_SMALL'\n",
    "                # print(str(key) + ' finished (small)')\n",
    "            # else:\n",
    "            leiden.loc[leiden['leiden'] == str(key), 'leiden'] = parent_cluster + '_' + leiden.loc[leiden['leiden'] == str(key), 'leiden']\n",
    "            print(str(key) + ' continuing')\n",
    "        else:\n",
    "            # may need to edit this to include last cluster ID before '_FINAL', as if there is more than one '_FINAL' cluster in a given round, they end up grouped together.\n",
    "            leiden.loc[leiden['leiden'] == str(key), 'leiden'] = parent_cluster + '_FINAL'\n",
    "            print(str(key) + ' finished')\n",
    "\n",
    "    return(leiden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2b8533f0-5c6d-41ff-82cb-d322e3e957bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # if first round, assign cluster to parent column\n",
    "#     if first_round == False:\n",
    "#         adata.obs['parent'] = adata.obs['leiden'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fe6617-df54-464a-aeea-4da6cca088dc",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load full adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0608908c-8a46-4d97-a8bb-2de398f92159",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('input/adata/midbrain/adata_spatial.pickle', 'rb') as f:\n",
    "    adata = pickle.load(f)\n",
    "    \n",
    "# make float 64 for reproducibility\n",
    "# https://github.com/theislab/scanpy/issues/313\n",
    "#adata.layers['counts'] = adata.layers['counts'].astype('float64')\n",
    "#adata.X = adata.X.astype('float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f16e7b3-b200-41b5-903e-1207a909a1fb",
   "metadata": {},
   "source": [
    "# Set seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a7d60b3c-f4be-4b62-8e07-25ec923b825a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    \"\"\"\"\n",
    "    Seed everything.\n",
    "    \"\"\"   \n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "seed_everything(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29753608-6a5f-4a80-aa81-77e873ef097e",
   "metadata": {},
   "source": [
    "# SCT decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fe3a1fbf-a7c5-4648-b48c-d066083c7734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 1000 × 4939\n",
       "    obs: 'x', 'y', 'sample_id', 'mouse_id', 'age', 'genotype', 'n_genes_by_counts', 'log1p_n_genes_by_counts', 'total_counts', 'log1p_total_counts', 'pct_counts_in_top_50_genes', 'pct_counts_in_top_100_genes', 'pct_counts_in_top_200_genes', 'pct_counts_in_top_500_genes', 'total_counts_mt', 'log1p_total_counts_mt', 'pct_counts_mt', 'total_counts_ribo', 'log1p_total_counts_ribo', 'pct_counts_ribo', 'total_counts_hb', 'log1p_total_counts_hb', 'pct_counts_hb', 'batch', 'n_genes', 'total_counts_Malat1', 'log1p_total_counts_Malat1', 'pct_counts_Malat1', 'x_orig', 'y_orig'\n",
       "    var: 'n_cells_by_counts', 'mean_counts', 'log1p_mean_counts', 'pct_dropout_by_counts', 'total_counts', 'log1p_total_counts', 'n_cells'\n",
       "    obsm: 'spatial'\n",
       "    layers: 'counts'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#adata = adata[adata.obs_names.isin(random.sample(adata.obs_names.to_list(), 1000))].copy()\n",
    "sc.pp.filter_genes(adata, min_cells=50)\n",
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cfb1a5-24ab-4282-aefd-ea3bd8b8eef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: .obsp[\"connectivities\"] have not been computed using umap\n",
      "{0: 0.9625806451612904, 1: 0, 2: 0, 3: 0}\n",
      "0 continuing\n",
      "1 finished\n",
      "2 finished\n",
      "3 finished\n"
     ]
    }
   ],
   "source": [
    "leiden, res = sct_cluster(adata, n_HVG=adata.shape[1])\n",
    "leiden_df = decide_cluster_outcome(adata, leiden, 's')\n",
    "adata.obs['current_leiden'] = leiden_df['leiden'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "987f4943-0a9b-4f50-9fdb-d900eeb2a60c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "while sum(['_FINAL' not in x for x in adata.obs['current_leiden'].unique()]):\n",
    "    \n",
    "    adatas = {}\n",
    "    for cl in adata.obs['current_leiden'].unique():\n",
    "        print(cl)\n",
    "        if '_FINAL' not in cl:\n",
    "            adatas[cl] = adata[adata.obs['current_leiden'] == cl].copy()\n",
    "            sc.pp.filter_genes(adatas[cl], min_cells=50)\n",
    "            print(adatas[cl].shape)\n",
    "            leiden, res = sct_cluster(adatas[cl], n_HVG=adata.shape[1])\n",
    "            leiden_df = decide_cluster_outcome(adatas[cl], leiden, cl)\n",
    "            adata.obs.loc[adata.obs['current_leiden'] == cl, 'current_leiden'] = leiden_df['leiden']\n",
    "            adata = adata[adata.obs['current_leiden'].str.startswith('s_').astype('bool'), :].copy() # remove singleton clusters\n",
    "            adata = adata[~adata.obs['current_leiden'].isna(), :].copy() # remove nan clusters\n",
    "            with open('input/adata/midbrain/adata2.pickle', 'wb') as f:\n",
    "                pickle.dump(adata, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "aea3d961-e4df-4234-8a46-f558934559e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 253055 × 19240\n",
       "    obs: 'x', 'y', 'sample_id', 'mouse_id', 'age', 'genotype', 'n_genes_by_counts', 'log1p_n_genes_by_counts', 'total_counts', 'log1p_total_counts', 'pct_counts_in_top_50_genes', 'pct_counts_in_top_100_genes', 'pct_counts_in_top_200_genes', 'pct_counts_in_top_500_genes', 'total_counts_mt', 'log1p_total_counts_mt', 'pct_counts_mt', 'total_counts_ribo', 'log1p_total_counts_ribo', 'pct_counts_ribo', 'total_counts_hb', 'log1p_total_counts_hb', 'pct_counts_hb', 'batch', 'n_genes', 'total_counts_Malat1', 'log1p_total_counts_Malat1', 'pct_counts_Malat1', 'x_orig', 'y_orig', 'current_leiden'\n",
       "    var: 'n_cells_by_counts', 'mean_counts', 'log1p_mean_counts', 'pct_dropout_by_counts', 'total_counts', 'log1p_total_counts', 'n_cells'\n",
       "    uns: 'log1p'\n",
       "    obsm: 'spatial'\n",
       "    layers: 'counts'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2cf2bbad-863e-4a3b-b671-a5be4d3f1422",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('input/adata/midbrain/adata.pickle', 'wb') as f:\n",
    "    pickle.dump(adata, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e07dbbd2-09da-4255-8cad-ce7f4c482971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "current_leiden\n",
       "s_1_0_0_0_0_FINAL       463\n",
       "s_1_0_0_0_FINAL         261\n",
       "s_1_0_0_1_0_1_FINAL     388\n",
       "s_1_0_0_1_0_FINAL       377\n",
       "s_1_0_0_1_1_FINAL       843\n",
       "                       ... \n",
       "s_3_2_2_0_1_FINAL       385\n",
       "s_3_2_2_0_FINAL         247\n",
       "s_3_2_2_1_FINAL         935\n",
       "s_3_2_FINAL            3505\n",
       "s_FINAL                 153\n",
       "Length: 146, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.obs.groupby('current_leiden').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de35b5e-c2fb-4bb8-9738-e3a56d76da1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
